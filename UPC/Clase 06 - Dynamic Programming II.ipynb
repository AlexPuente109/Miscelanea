{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase 06\n",
    "\n",
    "Para una mejor visualización entrar al siguiente [link]()\n",
    "\n",
    "# Requisitos previos\n",
    "\n",
    "* Programación Dinámica I\n",
    "* Principio de Optimalidad de Bellman\n",
    "\n",
    "## Problemas Clásicos usando DP - Parte 2\n",
    "\n",
    "### Matrix Chain Multiplication\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen $n$ matrices $A_{i}$ definidas por sus dimensiones en un arreglo $p_{i}$, tal que $A_{i} \\in \\mathbb{R}^{p_{i}\\times p_{i+1}}$, las cuales se quieren multiplicar usando la menor cantidad de operaciones posible. Esta forma óptima de multiplicación se debe obtener únicamente colocando paréntesis en donde convenga **sin reordenar** las matrices.\n",
    "\n",
    "Para resolver este problema usando fuerza bruta debemos considerar que tenemos la posibilidad de colocar $\\left\\lfloor\\frac{n+1}{2} \\right\\rfloor$ pares de paréntesis como máximo y que el resultado final debe ser una expresión correctamente balanceada. Esta cantidad de formas nos hace recordar a los números de Catalán, los cuales tienen un crecimiento asintótico de $O\\left(\\frac{4^{n}}{n^{\\frac{3}{2}}\\Pi}\\right)$: para nada eficiente.\n",
    "\n",
    "Sin embargo, podríamos analizar el problema con un estilo Divide and Conquer, considerando que si colocamos paréntesis para separar dos subsecuencias contiguas de la original, el problema se reduce a resolver ambas partes:\n",
    "\n",
    "$$ A_{1}\\cdot A_{2} \\ldots A_{n} = (A_{1}\\ldots A_{k})(A_{k+1}\\ldots A_{n}) $$\n",
    "\n",
    "En este momento, debemos considerar algunas cosas:\n",
    "\n",
    "1) El separar la secuencia en dichas partes nos dice que eventualmente multiplicaremos dos matrices de $p_{1}\\times p_{k+1}$ con una de $p_{k+1}\\times p_{n+1}$, dándonos un peor costo de $p_{1}p_{k+1}p_{n+1}$ mediante la multiplicación trivial de matrices.\n",
    "\n",
    "2) Luego de separar la secuencia, debemos resolver ambas partes de la *mejor manera* para que encajen con la solución eventual señalada en el punto 1, pero debemos notar que ambas soluciones son independientes entre sí y del valor generado por la división. Lo anterior nos sirve para probar que la resolución de ambas partes debe ser óptima y el problema cumple con el principio de Optimalidad de Bellman\n",
    "\n",
    "Con el análisis anterior, podemos plantear una recursión simple:\n",
    "\n",
    "$$ DP(L,R) = \\max\\limits_{L \\leq k < R}{\\left\\{DP(L,k) + DP(k+1,R) + p_{L}p_{k}p_{R+1}\\right\\}} $$\n",
    "\n",
    "Con $DP(i,i) = 0$, $\\forall i = 1, \\ldots, n$.\n",
    "\n",
    "Y usando nuestra técnica de almacenamiento podemos implementar la solucion, cuya complejidad es de $O(n^{3})$.\n",
    "\n",
    "### Longest Common Subsequence\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen dos cadenas $a$ y $b$ de longitudes $n$ y $m$, respectivamente; se desea dar la longitud de la subsecuencia de caracteres más larga que pertenezca a ambas cadenas.\n",
    "\n",
    "Para resolver este problema ya ni es necesario pensar en la solución con fuerza bruta, dado que la más óptima de ellas igual tendrá complejidad exponencial. Esto nos obliga a analizar un poco más las características de la solución.\n",
    "\n",
    "**Observación 1:** Al ser la respuesta una subsecuencia con la característica de que será la más larga de todas, entonces no hay diferencia entre procesar la respuesta de izquierda a derecha o de derecha a izquierda.\n",
    "\n",
    "Supongamos que hemos analizado y procesado la respuesta para los caracteres del $i$ hasta el $n$ en $a$ y del $j$ hasta el $m$ en $b$, entonces notemos que la respuesta de los caracteres restantes no se ve afectada por los que ya están procesados (uno puede verlo como si hubiese eliminado dichos caracteres), por lo que la solución para los restantes debe ser óptima también. Lo anterior nos ayuda a probar que el problema cumple con el principio de optimalidad de Bellman.\n",
    "\n",
    "Dado el análisis previo, podemos plantear la recursión para resolver el problema:\n",
    "\n",
    "$$ DP(i,j) = \\left\\{ \\begin{array}{cc} \\max{\\{DP(i-1,j), DP(i,j-1)\\}} &a_{i} \\neq b_{j} \\\\ 1 + DP(i-1,j-1) &a_{i} = b_{j} \\end{array}\\right. $$\n",
    "\n",
    "La expresión en palabras de la función recursiva se puede lograr fácilmente debido a que nuestro predicado está bien definido:\n",
    "\n",
    "La solución para los primeros $i$ y los primeros $j$ caracteres de $a$ y $b$ respectivamente tiene dos posibles casos: si los caracteres en dichas posiciones son diferentes, solo nos queda probar quitando alguno de los dos y tomar el valor máximo de las dos posibilidades; si los caracteres en dichas posiciones son iguales, nos conviene tomar a los dos y seguir con los demás (el hecho de que ya no se pruebe con quitar alguno de los dos caracteres es debido a que cualquiera de esos intentos no mejorará la respuesta final, por lo que es una transición innecesaria).\n",
    "\n",
    "Finalmente, usando almacenamiento, podemos resolver el problema en $O(n^{2})$.\n",
    "\n",
    "### Longest Increasing Subsequence\n",
    "\n",
    "El enunciado de este problema es el siguiente: Se tienen $n$ elementos que están sujetos a un orden parcial, se desea hallar la longitud de la subsecuencia ordenada más larga de todas.\n",
    "\n",
    "La idea usando fuerza bruta tiene complejidad exponencial, así que no nos conviene usarla en absoluto. En cambio, consideraremos el siguiente enfoque, parecido al que usamos en 1D Range Sum:\n",
    "\n",
    "Definimos la función $DP(i)$ como la longitud de la máxima subsecuencia que termina exactamente en la posición $i$, entonces esta función tiene la siguiente característica:\n",
    "\n",
    "$$ DP(i) = \\max\\limits_{j < i, a_{j} \\prec a_{i}}{\\{f(j) + 1\\}} $$\n",
    "\n",
    "Donde $f(j)$ es una función tal que halla el mejor ajuste para que el resultado de $i$ sea óptimo.\n",
    "\n",
    "Sin embargo, estas soluciones se pueden considerar como incrementales (es decir, se van agregando posibles elementos a la solución) y, por ello, el elemento nuevo no puede afectar a lo que se procesó en el pasado, así que son independientes. Recordemos que si los objetivos de optimización son independientes, entonces cada parte por sí sola es óptima: el problema cumple con el principio de optimalidad de Bellman.\n",
    "\n",
    "Dado que el problema cumple con nuestro principio de optimalidad, podemos notar que $f = DP$ pues el $j$ *ignora* el futuro resultado de $i$ para procesarse a sí mismo. Finalmente llegamos a que:\n",
    "\n",
    "$$ DP(i) = \\max\\limits_{j < i, a_{j} \\prec a_{i}}{\\{DP(j) + 1\\}} $$\n",
    "\n",
    "Lo cual puede ser implementado de diferentes maneras, siendo la menos eficiente un $O(n^{2})$. En clase se explicará la forma $O(nlogn)$ usando Binary Search.\n",
    "\n",
    "## Reconstrucción de Soluciones\n",
    "\n",
    "Para reconstruir las soluciones procesadas por DP, es necesario notar la naturaleza de las transiciones entre estados. Cada estado tiene un conjunto de transiciones que logran obtener una respuesta óptima (dependiendo del problema, podríamos elegir cualquiera o alguno con una característica especial), por lo que basta con almacenar la transición adecuada mediante una tabla extra (considerando la poca cantidad de opciones de transición por estado). Luego de almacenar las transiciones óptimas por estado, podemos recuperar la solución mediante una forma iterativa o incluso recursiva, que tendrá por complejidad $O(\\text{longitud de la respuesta})$, siempre llamando desde el estado inicial de solución.\n",
    "\n",
    "### Ejemplo - Knapsack Problem\n",
    "\n",
    "El algoritmo recursivo para resolver el problema de la mochila es el siguiente:\n",
    "\n",
    "```Python\n",
    "def Knapsack(pos,left):\n",
    "    if pos == n: return 0\n",
    "    if vis[pos][left]: return memo[pos][left]\n",
    "    ans = Knapsack(pos+1,left)\n",
    "    if left >= w[pos]:\n",
    "        ans = max(ans,v[pos] + Knapsack(pos+1,left-w[pos]))\n",
    "    vis[pos][left] = True\n",
    "    return memo[pos][left] = ans\n",
    "```\n",
    "\n",
    "Y por cada estado tenemos la opción entre usar o no usar el elemento $pos$, así que solamente crearemos un arreglo booleano extra que mantenga $True$ si el elemento $pos$ fue tomado y $False$ si no lo fue.\n",
    "\n",
    "```Python\n",
    "def Knapsack(pos,left):\n",
    "    if pos == n: return 0\n",
    "    if vis[pos][left]: return memo[pos][left]\n",
    "    ans = Knapsack(pos+1,left)\n",
    "    choice[pos][left] = False # Asumo que no me conviene tomarlo\n",
    "    if left >= w[pos]:\n",
    "        if ans < v[pos] + Knapsack(pos+1,left-w[pos]): # Me conviene tomarlo\n",
    "            ans = v[pos] + Knapsack(pos+1,left-w[pos]) \n",
    "            choice[pos][left] = True # Actualizo la decision optima\n",
    "    vis[pos][left] = True\n",
    "    return memo[pos][left] = ans\n",
    "```\n",
    "\n",
    "Entonces podemos reconstruir la solución usando la siguiente función recursiva:\n",
    "\n",
    "```Python\n",
    "def KnapsackSolution(pos,left,ans):\n",
    "    if pos == n: return\n",
    "    if choice[pos][left]:\n",
    "        ans.append(pos)\n",
    "        left -= w[pos]\n",
    "    KnapsackSolution(pos+1,left,ans)\n",
    "```\n",
    "\n",
    "La cual tiene una complejidad de $O(n)$, pues solamente hay una transición en cada paso.\n",
    "\n",
    "## Contest Corto de DP\n",
    "\n",
    "* [GPC-UPC DP Short Contest](https://codeforces.com/group/Hz7jTE3LqO/contest/250369)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
